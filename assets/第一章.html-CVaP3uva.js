import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as o,a as l,o as a}from"./app-CGZRCIfw.js";const n={};function r(s,t){return a(),o("div",null,t[0]||(t[0]=[l(`<h2 id="一、工具" tabindex="-1"><a class="header-anchor" href="#一、工具"><span>一、工具</span></a></h2><div style="text-align:center;font-size:50px;"> 🍍 ollama 介绍 </div><p><span style="color:red;font-weight:bold;"> ollama </span> 是一个开源、本地化部署的机器学习框架，专为高效运行和管理大型语言模型（LLM）设计。它支持文本生成、对话交互、代码编写等自然语言处理任务，允许用户在本地设备（而非云端）直接运行模型，兼顾隐私保护与性能优化。 Ollama为开发者、企业用户及隐私敏感场景提供了<strong>自主可控的AI解决方案</strong>，其开源特性与本地化优势使其在AI工具链中占据独特地位。对于希望掌握AI技术主权或构建定制化应用的用户，Ollama是高效且安全的选择。</p><div style="color:#096dd9;font-weight:bold;">核心功能有：</div><p><strong>1、模型管理</strong>： 支持从官方库（如Llama 2、DeepSeek-R1）或自定义路径拉取模型，提供<code>ollama pull/list/rm</code>等命令简化操作。 模型以Docker容器封装，确保跨平台一致性。 <strong>2、高效推理</strong>： 通过GPU/CPU加速提升推理速度，支持量化技术（如8位压缩）优化资源占用。<strong>灵活接口</strong>：提供命令行（CLI）、HTTP API及WebUI多种交互方式，开发者可轻松集成至应用。 <strong>3、跨平台支持</strong>： 兼容Windows、macOS、Linux，安装脚本自动化部署。</p><div style="color:#096dd9;font-weight:bold;">技术亮点具备：</div><p><strong>1、隐私优先</strong>：所有数据处理均在本地完成，避免敏感信息上传云端。 <strong>2、开源生态</strong>：代码遵循MIT协议，支持自定义模型上传与参数调整。 <strong>3、可扩展性</strong>：支持模型微调（Fine-tuning），用户可用自有数据优化模型输出。</p><div style="color:#096dd9;font-weight:bold;">典型应用场景：</div><p><strong>1、教育</strong>：个性化学习内容生成、作业自动批改。 <strong>2、商业</strong>：客户服务自动化、市场营销文案创作。 <strong>3、开发</strong>：快速搭建AI原型，结合LangChain等工具构建知识库应用。</p><div style="color:#096dd9;font-weight:bold;">用户体验优化：</div><p><strong>1、WebUI部署</strong>：支持LobeChat、OpenWebUI等可视化界面，提升交互便捷性。 <strong>2、性能调优</strong>：通过环境变量（如<code>OLLAMA_DEVICE=gpu</code>）指定硬件加速，日志级别控制。</p><div style="color:#096dd9;font-weight:bold;">局限性：</div><p><strong>1、模型下载速度</strong>：国内用户可能需使用镜像加速（如GitHub或ModelScope）。 <strong>2、硬件依赖</strong>：运行大型模型需较高内存和显存（如DeepSeek-R1需1.5B参数支持）。</p><div style="text-align:center;font-size:30px;"> 🍍 ragflow 介绍 </div><p><span style="color:red;font-weight:bold;"> RAGFlow </span>新一代检索增强生成引擎。 RAGFlow（<strong>R</strong>etrieval-<strong>A</strong>ugmented <strong>G</strong>eneration <strong>Flow</strong>）是一种结合<strong>检索增强生成（RAG）<strong>和</strong>工作流优化</strong>的技术架构，旨在提升生成式AI系统的效率与准确性。其核心思想是通过动态调控检索与生成流程，使AI在依赖外部知识库时，能更智能、高效地生成内容。 RAGFlow通过<strong>检索+生成+工作流优化</strong>的闭环设计，重新定义了AI与知识库的交互方式，尤其适合需要<strong>高效、精准、可控</strong>生成内容的场景。对于希望构建私有化知识库或优化AI应答质量的企业与个人，RAGFlow提供了开箱即用的解决方案。 它的<span style="color:#096dd9;font-weight:bold;">核心优势</span> 在于：</p><p><strong>1、动态优化</strong>：自动调整检索与生成步骤，减少冗余计算。 <strong>2、多任务并行</strong>：快速响应复杂查询，提升系统吞吐量。 <strong>3、反馈机制</strong>：根据生成结果优化检索策略，提高回答可靠性。 <strong>4、多源整合</strong>：无缝对接数据库、文档库、API等异构数据源。 <strong>5、成本优化</strong>：通过精准检索降低资源消耗，支持本地化部署。</p><div style="color:#096dd9;font-weight:bold;">技术实现</div><p><strong>1、深度文档理解</strong>：</p><ul><li>支持PDF、Word、Excel、图片等多格式解析，自动提取关键信息。</li><li>采用模板化分块技术（如RAPTOR算法），对长文档进行分层总结，提升检索效率。</li></ul><p><strong>2、可视化工作流</strong>：</p><ul><li><p>提供从文档上传、解析到问答测试的全流程图形化界面。</p></li><li><p>支持自定义嵌入模型（Embedding Model）和重排模型（Rerank Model），优化检索精度。</p></li><li><p><strong>3、自动化管理</strong>：</p><ul><li>内置Self-RAG机制，自动评估生成质量并调整策略。</li><li>支持与主流大模型（如GPT、DeepSeek）及本地模型（如Ollama）集成。</li></ul></li></ul><div style="color:#096dd9;font-weight:bold;">典型应用场景</div><p><strong>1、智能客服</strong>：实时检索产品文档、FAQ库，生成个性化回复。 <strong>2、知识库搭建</strong>：将非结构化文档转化为可检索知识库，支持精准问答。 <strong>3、数据分析</strong>：结合外部数据源生成分析报告，辅助决策。 <strong>4、教育辅助</strong>：解析教材、论文，提供学习资料与难题解答。 <strong>5、内容创作</strong>：为博客、新闻等场景提供灵感素材，提升创作效率。</p><h2 id="二、下载和安装" tabindex="-1"><a class="header-anchor" href="#二、下载和安装"><span>二、下载和安装</span></a></h2><div style="text-align:center;font-size:30px;"> 🔱 ollama下载和安装 </div><h3 id="_1、下载" tabindex="-1"><a class="header-anchor" href="#_1、下载"><span>1、下载</span></a></h3><p>官方地址：https://ollama.com</p><h3 id="_2、安装-验证安装-配置环境变量" tabindex="-1"><a class="header-anchor" href="#_2、安装-验证安装-配置环境变量"><span>2、安装 | 验证安装 | 配置环境变量</span></a></h3><p><a href="./videos/ollama.mp4">安装视频</a></p><div style="text-align:center;font-size:30px;"> 🔱 ragflow下载和安装 </div><h3 id="_1、下载-1" tabindex="-1"><a class="header-anchor" href="#_1、下载-1"><span>1、下载</span></a></h3><p>官网地址：https://ragflow.io/docs/dev/</p><h3 id="_2、安装-验证安装-配置环境变量-1" tabindex="-1"><a class="header-anchor" href="#_2、安装-验证安装-配置环境变量-1"><span>2、安装 | 验证安装 | 配置环境变量</span></a></h3><p><a href="./videos/ollama.mp4">安装视频</a></p><h2 id="三、整合-ollama-和-ragflow" tabindex="-1"><a class="header-anchor" href="#三、整合-ollama-和-ragflow"><span>三、整合 ollama 和 ragflow</span></a></h2><p>sudo curl -L &quot;https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose ————————————————</p><pre><code>                        版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。
</code></pre><p>原文链接：https://blog.csdn.net/qq_39779233/article/details/142526090</p>`,38)]))}const g=e(n,[["render",r],["__file","第一章.html.vue"]]),p=JSON.parse('{"path":"/aiandartificialintelligence/%E7%AC%AC%E4%B8%80%E7%AB%A0.html","title":"ollama 和 ragflow 搭建私有化AI平台","lang":"zh-CN","frontmatter":{"title":"ollama 和 ragflow 搭建私有化AI平台","index":false,"isOriginal":true,"category":"AI和人工智能","tag":"智能AI","date":"2025-03-29T00:00:00.000Z","description":"一、工具 🍍 ollama 介绍 ollama 是一个开源、本地化部署的机器学习框架，专为高效运行和管理大型语言模型（LLM）设计。它支持文本生成、对话交互、代码编写等自然语言处理任务，允许用户在本地设备（而非云端）直接运行模型，兼顾隐私保护与性能优化。 Ollama为开发者、企业用户及隐私敏感场景提供了自主可控的AI解决方案，其开源特性与本地化优势...","head":[["meta",{"property":"og:url","content":"https://mister-hope.github.io/backend-book/aiandartificialintelligence/%E7%AC%AC%E4%B8%80%E7%AB%A0.html"}],["meta",{"property":"og:site_name","content":"极速蜗牛"}],["meta",{"property":"og:title","content":"ollama 和 ragflow 搭建私有化AI平台"}],["meta",{"property":"og:description","content":"一、工具 🍍 ollama 介绍 ollama 是一个开源、本地化部署的机器学习框架，专为高效运行和管理大型语言模型（LLM）设计。它支持文本生成、对话交互、代码编写等自然语言处理任务，允许用户在本地设备（而非云端）直接运行模型，兼顾隐私保护与性能优化。 Ollama为开发者、企业用户及隐私敏感场景提供了自主可控的AI解决方案，其开源特性与本地化优势..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-06-14T05:43:04.000Z"}],["meta",{"property":"article:author","content":"青衣"}],["meta",{"property":"article:tag","content":"智能AI"}],["meta",{"property":"article:published_time","content":"2025-03-29T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-06-14T05:43:04.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"ollama 和 ragflow 搭建私有化AI平台\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-03-29T00:00:00.000Z\\",\\"dateModified\\":\\"2025-06-14T05:43:04.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"青衣\\",\\"url\\":\\"https://mister-hope.com\\"}]}"]]},"headers":[{"level":2,"title":"一、工具","slug":"一、工具","link":"#一、工具","children":[]},{"level":2,"title":"二、下载和安装","slug":"二、下载和安装","link":"#二、下载和安装","children":[{"level":3,"title":"1、下载","slug":"_1、下载","link":"#_1、下载","children":[]},{"level":3,"title":"2、安装 | 验证安装 | 配置环境变量","slug":"_2、安装-验证安装-配置环境变量","link":"#_2、安装-验证安装-配置环境变量","children":[]},{"level":3,"title":"1、下载","slug":"_1、下载-1","link":"#_1、下载-1","children":[]},{"level":3,"title":"2、安装 | 验证安装 | 配置环境变量","slug":"_2、安装-验证安装-配置环境变量-1","link":"#_2、安装-验证安装-配置环境变量-1","children":[]}]},{"level":2,"title":"三、整合 ollama 和 ragflow","slug":"三、整合-ollama-和-ragflow","link":"#三、整合-ollama-和-ragflow","children":[]}],"git":{"createdTime":1749879784000,"updatedTime":1749879784000,"contributors":[{"name":"tsing-dong","email":"ld320321@163.com","commits":1}]},"readingTime":{"minutes":4.88,"words":1465},"filePathRelative":"aiandartificialintelligence/第一章.md","localizedDate":"2025年3月29日","excerpt":"<h2>一、工具</h2>\\n<div style=\\"text-align: center; font-size: 50px\\"> 🍍 ollama 介绍 </div>\\n<p><span style=\\"color: red; font-weight:bold\\"> ollama </span> 是一个开源、本地化部署的机器学习框架，专为高效运行和管理大型语言模型（LLM）设计。它支持文本生成、对话交互、代码编写等自然语言处理任务，允许用户在本地设备（而非云端）直接运行模型，兼顾隐私保护与性能优化。\\nOllama为开发者、企业用户及隐私敏感场景提供了<strong>自主可控的AI解决方案</strong>，其开源特性与本地化优势使其在AI工具链中占据独特地位。对于希望掌握AI技术主权或构建定制化应用的用户，Ollama是高效且安全的选择。</p>","autoDesc":true}');export{g as comp,p as data};
